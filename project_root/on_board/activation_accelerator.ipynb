{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59299ab3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pynq.pl_server.global_state\n",
    "pynq.pl_server.global_state.clear_global_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e9d1adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PYNQ and Torch environment loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from pynq import Overlay, allocate\n",
    "import time\n",
    "import os\n",
    "\n",
    "print(\"PYNQ and Torch environment loaded successfully.\")\n",
    "\n",
    "# ====== 1. 全局常量定义 ======\n",
    "# 数据维度\n",
    "N_DIM = 64\n",
    "D_DIM = 768\n",
    "BUFFER_SHAPE = (N_DIM * D_DIM,)\n",
    "\n",
    "# 文件路径\n",
    "BITSTREAM_PATH = \"activation_accelerator.bit\"\n",
    "\n",
    "# 从 Vivado 时序报告中确认的核心时钟频率 (MHz)\n",
    "CLOCK_FREQ_MHZ = 250.0\n",
    "\n",
    "# 单个 bf16 元素占用的字节数\n",
    "BYTES_PER_ELEMENT = 2\n",
    "\n",
    "# 每次计算涉及的总数据量 (从 BRAM/URAM 读一次, 写一次)\n",
    "TOTAL_BYTES_MOVED = N_DIM * D_DIM * BYTES_PER_ELEMENT * 2 \n",
    "\n",
    "# Elementwise 操作的总操作数 (用于计算 GOPS)\n",
    "TOTAL_ELEMENTWISE_OPS = N_DIM * D_DIM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5eef3d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading bitstream: activation_accelerator.bit\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%pybind11/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Overlay in module pynq.overlay:\n",
      "\n",
      "<pynq.overlay.Overlay object>\n",
      "    Default documentation for overlay activation_accelerator.bit. The following\n",
      "    attributes are available on this overlay:\n",
      "    \n",
      "    IP Blocks\n",
      "    ----------\n",
      "    activation_accelerat_0 : pynq.overlay.DefaultIP\n",
      "    zynq_ultra_ps_e_0    : pynq.overlay.DefaultIP\n",
      "    \n",
      "    Hierarchies\n",
      "    -----------\n",
      "    None\n",
      "    \n",
      "    Interrupts\n",
      "    ----------\n",
      "    None\n",
      "    \n",
      "    GPIO Outputs\n",
      "    ------------\n",
      "    None\n",
      "    \n",
      "    Memories\n",
      "    ------------\n",
      "    PSDDR                : Memory\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ====== 2. 加载 Overlay 和数据 ======\n",
    "print(f\"Loading bitstream: {BITSTREAM_PATH}\")\n",
    "overlay = Overlay(BITSTREAM_PATH)\n",
    "help(overlay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e6330dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on DefaultIP in module pynq.overlay object:\n",
      "\n",
      "class DefaultIP(builtins.object)\n",
      " |  DefaultIP(description)\n",
      " |  \n",
      " |  Driver for an IP without a more specific driver\n",
      " |  \n",
      " |  This driver wraps an MMIO device and provides a base class\n",
      " |  for more specific drivers written later. It also provides\n",
      " |  access to GPIO outputs and interrupts inputs via attributes. More specific\n",
      " |  drivers should inherit from `DefaultIP` and include a\n",
      " |  `bindto` entry containing all of the IP that the driver\n",
      " |  should bind to. Subclasses meeting these requirements will\n",
      " |  automatically be registered.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  mmio : pynq.MMIO\n",
      " |      Underlying MMIO driver for the device\n",
      " |  _interrupts : dict\n",
      " |      Subset of the PL.interrupt_pins related to this IP\n",
      " |  _gpio : dict\n",
      " |      Subset of the PL.gpio_dict related to this IP\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, description)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  read(self, offset=0)\n",
      " |      Read from the MMIO device\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      offset : int\n",
      " |          Address to read\n",
      " |  \n",
      " |  write(self, offset, value)\n",
      " |      Write to the MMIO device\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      offset : int\n",
      " |          Address to write to\n",
      " |      value : int or bytes\n",
      " |          Data to write\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  register_map\n",
      " |  \n",
      " |  signature\n",
      " |      The signature of the `call` method\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n",
      "Bitstream loaded. IP core handle '<pynq.overlay.DefaultIP object at 0xffff44ea0c70>' is ready.\n"
     ]
    }
   ],
   "source": [
    "# 获取 IP 句柄。PYNQ 将其识别为 DefaultIP 类型，这是正确的。\n",
    "acc_ip = overlay.activation_accelerat_0\n",
    "help(acc_ip)\n",
    "print(f\"Bitstream loaded. IP core handle '{acc_ip}' is ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75e7dc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================\n",
    "#  >>> 最终确认版: HLS IP 核的 AXI-Lite 寄存器地址偏移 <<<\n",
    "#  (根据您 HLS 在合并接口后新生成的 xactivation_accelerator_hw.h 文件)\n",
    "# =================================================================================\n",
    "ADDR_AP_CTRL   = 0x00\n",
    "ADDR_IN0_LOW   = 0x10\n",
    "ADDR_IN0_HIGH  = 0x14\n",
    "ADDR_IN1_LOW   = 0x1c\n",
    "ADDR_IN1_HIGH  = 0x20\n",
    "ADDR_OUT_LOW   = 0x28\n",
    "ADDR_OUT_HIGH  = 0x2c\n",
    "ADDR_STAGE     = 0x34 # 注意: 地址已根据新 hw.h 文件更新\n",
    "ADDR_CONFIG    = 0x3c # 注意: 地址已根据新 hw.h 文件更新\n",
    "# =================================================================================\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "232c29a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell 1 finished\n"
     ]
    }
   ],
   "source": [
    "# 竞赛函数与您硬件的 Opcode 映射\n",
    "OPCODE_MAP = {\n",
    "    'Softmax': 9, 'LayerNorm': 6, 'RMSNorm': 5, 'SiLU': 4,\n",
    "    'GELU': 8, 'Add': 0, 'Mul': 7,\n",
    "}\n",
    "\n",
    "# 按照竞赛权重顺序排列的待测函数列表\n",
    "FUNCTIONS_TO_TEST = ['Softmax', 'LayerNorm', 'RMSNorm', 'SiLU', 'GELU', 'Add', 'Mul']\n",
    "\n",
    "# 精度评分参数\n",
    "LOSSLESS_THRESHOLD = 1e-3\n",
    "print(\"Cell 1 finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7176ac7c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell 2 finished\n"
     ]
    }
   ],
   "source": [
    "def to_float32_from_bits(bf16_bits_np: np.ndarray):\n",
    "    \"\"\"将 uint16 的 bf16 位模式数组转换为 float32 numpy 数组\"\"\"\n",
    "    assert bf16_bits_np.dtype == np.uint16\n",
    "    u32s = bf16_bits_np.astype(np.uint32) << 16\n",
    "    return u32s.view(np.float32)\n",
    "\n",
    "def calculate_accuracy_score(fpga_out_bits_np: np.ndarray, golden_ref_pt: torch.Tensor):\n",
    "    \"\"\"根据竞赛规则计算 L2 误差和精度分数 (修正版)\"\"\"\n",
    "    fpga_out_f32 = to_float32_from_bits(fpga_out_bits_np)\n",
    "    golden_ref_f32 = golden_ref_pt.to(torch.float32).cpu().numpy().flatten()\n",
    "\n",
    "    # --- 1. 严格检查特殊值 (NaN 和 Inf) ---\n",
    "    nan_mask_fpga = np.isnan(fpga_out_f32)\n",
    "    nan_mask_golden = np.isnan(golden_ref_f32)\n",
    "    if np.any(nan_mask_fpga != nan_mask_golden):\n",
    "        mismatched_special_count = np.count_nonzero(nan_mask_fpga != nan_mask_golden)\n",
    "        print(f\"  [Accuracy FATAL] Mismatch in NaN locations! Count: {mismatched_special_count}\")\n",
    "        return float('inf'), 0.0, mismatched_special_count\n",
    "\n",
    "    inf_mask_fpga = np.isinf(fpga_out_f32)\n",
    "    inf_mask_golden = np.isinf(golden_ref_f32)\n",
    "    if np.any(inf_mask_fpga != inf_mask_golden):\n",
    "        mismatched_special_count = np.count_nonzero(inf_mask_fpga != inf_mask_golden)\n",
    "        print(f\"  [Accuracy FATAL] Mismatch in Inf locations! Count: {mismatched_special_count}\")\n",
    "        return float('inf'), 0.0, mismatched_special_count\n",
    "        \n",
    "    # 检查 Inf 的符号是否匹配\n",
    "    if np.any(inf_mask_golden): # 只有当存在 Inf 时才检查\n",
    "      if not np.all(fpga_out_f32[inf_mask_golden] == golden_ref_f32[inf_mask_golden]):\n",
    "          mismatched_special_count = np.count_nonzero(fpga_out_f32[inf_mask_golden] != golden_ref_f32[inf_mask_golden])\n",
    "          print(f\"  [Accuracy FATAL] Mismatch in Inf signs! Count: {mismatched_special_count}\")\n",
    "          return float('inf'), 0.0, mismatched_special_count\n",
    "\n",
    "    # --- 2. 计算常规数值的 L2 误差 ---\n",
    "    # 正确的 valid_indices：排除所有 NaN 和 Inf\n",
    "    valid_indices = ~nan_mask_golden & ~inf_mask_golden\n",
    "    \n",
    "    # 如果所有值都是特殊值，那么到这里已经通过了\n",
    "    if not np.any(valid_indices):\n",
    "        return 0.0, 1.0, 0\n",
    "\n",
    "    numerator = np.linalg.norm(fpga_out_f32[valid_indices] - golden_ref_f32[valid_indices])\n",
    "    denominator = np.linalg.norm(golden_ref_f32[valid_indices])\n",
    "    \n",
    "    if denominator < 1e-12:\n",
    "        relative_l2_error = 0.0 if numerator < 1e-12 else float('inf')\n",
    "    else:\n",
    "        relative_l2_error = numerator / denominator\n",
    "    \n",
    "    # --- 3. 计算精度分数 ---\n",
    "    ef = relative_l2_error\n",
    "    LOSSLESS_THRESHOLD = 1e-3 # 与脚本其他部分保持一致\n",
    "    if ef <= LOSSLESS_THRESHOLD:\n",
    "        accuracy_score = 1.0\n",
    "    elif ef < 100 * LOSSLESS_THRESHOLD:\n",
    "        accuracy_score = (np.log(100 * LOSSLESS_THRESHOLD) - np.log(ef)) / np.log(100)\n",
    "    else:\n",
    "        accuracy_score = 0.0\n",
    "        \n",
    "    # --- 4. 计算常规数值中，位模式不匹配的个数 ---\n",
    "    fpga_bits_valid = fpga_out_bits_np[valid_indices]\n",
    "    # golden_bits_valid = golden_ref_pt.view(torch.uint16).cpu().numpy().flatten()[valid_indices]\n",
    "    golden_bits_valid = golden_ref_pt.view(torch.int16).cpu().numpy().flatten()[valid_indices]\n",
    "    diff_count = np.count_nonzero(fpga_bits_valid != golden_bits_valid)\n",
    "\n",
    "    return ef, accuracy_score, diff_count\n",
    "print(\"Cell 2 finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f15d1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_BIN_PATH = \"X_test_tensor_bf16.bin\"\n",
    "Y_BIN_PATH = \"Y_test_tensor_bf16.bin\"\n",
    "REF_DIR = \"./refs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ee78c1b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading test vectors: X_test_tensor_bf16.bin, Y_test_tensor_bf16.bin\n",
      "Loading golden reference files...\n",
      "  - Loaded reference for Softmax\n",
      "  - Loaded reference for LayerNorm\n",
      "  - Loaded reference for RMSNorm\n",
      "  - Loaded reference for SiLU\n",
      "  - Loaded reference for GELU\n",
      "  - Loaded reference for Add\n",
      "  - Loaded reference for Mul\n",
      "\n",
      "Allocating PYNQ buffers for DMA...\n",
      "Buffers allocated.\n",
      "Input data copied to DDR.\n",
      "Cell 3 finished\n"
     ]
    }
   ],
   "source": [
    "# 加载输入向量\n",
    "print(f\"\\nLoading test vectors: {X_BIN_PATH}, {Y_BIN_PATH}\")\n",
    "X_test_bits = np.fromfile(X_BIN_PATH, dtype=np.uint16)\n",
    "Y_test_bits = np.fromfile(Y_BIN_PATH, dtype=np.uint16)\n",
    "\n",
    "# 加载所有黄金参考\n",
    "print(\"Loading golden reference files...\")\n",
    "golden_refs = {}\n",
    "for func_name in FUNCTIONS_TO_TEST:\n",
    "    ref_filename = f\"ref_{func_name.lower()}_bf16.pt\"\n",
    "    ref_path = os.path.join(REF_DIR, ref_filename)\n",
    "    golden_refs[func_name] = torch.load(ref_path, weights_only=True)\n",
    "    print(f\"  - Loaded reference for {func_name}\")\n",
    "\n",
    "# 在板上 DDR 分配物理连续内存\n",
    "print(\"\\nAllocating PYNQ buffers for DMA...\")\n",
    "in0_buffer = allocate(shape=BUFFER_SHAPE, dtype=np.uint16)\n",
    "in1_buffer = allocate(shape=BUFFER_SHAPE, dtype=np.uint16)\n",
    "out_buffer = allocate(shape=BUFFER_SHAPE, dtype=np.uint16)\n",
    "print(\"Buffers allocated.\")\n",
    "\n",
    "# 拷贝数据到 DDR 并刷新\n",
    "in0_buffer[:] = X_test_bits\n",
    "in1_buffer[:] = Y_test_bits\n",
    "in0_buffer.flush()\n",
    "in1_buffer.flush()\n",
    "print(\"Input data copied to DDR.\")\n",
    "print(\"Cell 3 finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59ac4867",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DDR buffer addresses written to IP core.\n",
      "\n",
      "--- Executing STAGE 0: Load data from DDR to on-chip memory ---\n",
      "STAGE 0 complete.\n",
      "\n",
      "--- Testing: Softmax ---\n",
      "  Latency (Stage 1): 0.8447 ms\n",
      "  Relative L2 Error (εf): 1.132788e-03\n",
      "  Mismatched Elements (non-NaN): 19133\n",
      "  Accuracy Score (Af): 0.972926\n",
      "  ---------------- Performance Metrics -----------------\n",
      "  Clock Frequency (from report): 250.0 MHz\n",
      "  Throughput: 1183.83 Tensors/sec\n",
      "  Effective On-Chip Bandwidth: 221.97 MB/s\n",
      "  Compute Power: N/A (Reduction-based)\n",
      "  ----------------------------------------------------\n",
      "  [DEBUG] Mismatch detected. Performing detailed row-by-row analysis...\n",
      "  [Analysis Result] A global mismatch was detected, but the per-row analysis script failed to pinpoint the cause.\n",
      "-------------------------\n",
      "\n",
      "--- Testing: LayerNorm ---\n",
      "  Latency (Stage 1): 0.8254 ms\n",
      "  Relative L2 Error (εf): 9.781953e-04\n",
      "  Mismatched Elements (non-NaN): 15686\n",
      "  Accuracy Score (Af): 1.000000\n",
      "  ---------------- Performance Metrics -----------------\n",
      "  Clock Frequency (from report): 250.0 MHz\n",
      "  Throughput: 1211.53 Tensors/sec\n",
      "  Effective On-Chip Bandwidth: 227.16 MB/s\n",
      "  Compute Power: N/A (Reduction-based)\n",
      "  ----------------------------------------------------\n",
      "-------------------------\n",
      "\n",
      "--- Testing: RMSNorm ---\n",
      "  Latency (Stage 1): 0.8476 ms\n",
      "  Relative L2 Error (εf): 9.242338e-04\n",
      "  Mismatched Elements (non-NaN): 17366\n",
      "  Accuracy Score (Af): 1.000000\n",
      "  ---------------- Performance Metrics -----------------\n",
      "  Clock Frequency (from report): 250.0 MHz\n",
      "  Throughput: 1179.83 Tensors/sec\n",
      "  Effective On-Chip Bandwidth: 221.22 MB/s\n",
      "  Compute Power: N/A (Reduction-based)\n",
      "  ----------------------------------------------------\n",
      "-------------------------\n",
      "\n",
      "--- Testing: SiLU ---\n",
      "  Latency (Stage 1): 0.3107 ms\n",
      "  Relative L2 Error (εf): 0.000000e+00\n",
      "  Mismatched Elements (non-NaN): 18491\n",
      "  Accuracy Score (Af): 1.000000\n",
      "  ---------------- Performance Metrics -----------------\n",
      "  Clock Frequency (from report): 250.0 MHz\n",
      "  Throughput: 3218.96 Tensors/sec\n",
      "  Effective On-Chip Bandwidth: 603.55 MB/s\n",
      "  Compute Power: 0.16 GOPS\n",
      "  ----------------------------------------------------\n",
      "-------------------------\n",
      "\n",
      "--- Testing: GELU ---\n",
      "  Latency (Stage 1): 0.3164 ms\n",
      "  Relative L2 Error (εf): 0.000000e+00\n",
      "  Mismatched Elements (non-NaN): 18940\n",
      "  Accuracy Score (Af): 1.000000\n",
      "  ---------------- Performance Metrics -----------------\n",
      "  Clock Frequency (from report): 250.0 MHz\n",
      "  Throughput: 3160.74 Tensors/sec\n",
      "  Effective On-Chip Bandwidth: 592.64 MB/s\n",
      "  Compute Power: 0.16 GOPS\n",
      "  ----------------------------------------------------\n",
      "-------------------------\n",
      "\n",
      "--- Testing: Add ---\n",
      "  Latency (Stage 1): 0.3231 ms\n",
      "  Relative L2 Error (εf): 0.000000e+00\n",
      "  Mismatched Elements (non-NaN): 16965\n",
      "  Accuracy Score (Af): 1.000000\n",
      "  ---------------- Performance Metrics -----------------\n",
      "  Clock Frequency (from report): 250.0 MHz\n",
      "  Throughput: 3095.43 Tensors/sec\n",
      "  Effective On-Chip Bandwidth: 580.39 MB/s\n",
      "  Compute Power: 0.15 GOPS\n",
      "  ----------------------------------------------------\n",
      "-------------------------\n",
      "\n",
      "--- Testing: Mul ---\n",
      "  Latency (Stage 1): 0.3295 ms\n",
      "  Relative L2 Error (εf): 3.373343e-04\n",
      "  Mismatched Elements (non-NaN): 15429\n",
      "  Accuracy Score (Af): 1.000000\n",
      "  ---------------- Performance Metrics -----------------\n",
      "  Clock Frequency (from report): 250.0 MHz\n",
      "  Throughput: 3034.95 Tensors/sec\n",
      "  Effective On-Chip Bandwidth: 569.05 MB/s\n",
      "  Compute Power: 0.15 GOPS\n",
      "  ----------------------------------------------------\n",
      "-------------------------\n",
      "\n",
      "Cell 4 finished\n"
     ]
    }
   ],
   "source": [
    "def run_stage_and_wait(stage, config=0, timeout_s=15):\n",
    "    \"\"\"一个封装好的函数，用于执行一个阶段并等待其完成\"\"\"\n",
    "    acc_ip.write(ADDR_CONFIG, config)\n",
    "    acc_ip.write(ADDR_STAGE, stage)\n",
    "    acc_ip.write(ADDR_AP_CTRL, 1) # ap_start\n",
    "    \n",
    "    t_start = time.time()\n",
    "    while (acc_ip.read(ADDR_AP_CTRL) & 0x2) == 0: # 轮询 ap_done (bit 1)\n",
    "        if time.time() - t_start > timeout_s:\n",
    "            raise TimeoutError(f\"IP execution timed out on stage={stage}, config={config}!\")\n",
    "        time.sleep(0.0001)\n",
    "\n",
    "# ====== 3. 执行测试 ======\n",
    "# 获取缓冲区的物理地址\n",
    "pa_in0 = in0_buffer.physical_address\n",
    "pa_in1 = in1_buffer.physical_address\n",
    "pa_out = out_buffer.physical_address\n",
    "\n",
    "# 将64位物理地址写入 IP 核的相应寄存器\n",
    "acc_ip.write(ADDR_IN0_LOW, pa_in0 & 0xFFFFFFFF)\n",
    "acc_ip.write(ADDR_IN0_HIGH, pa_in0 >> 32)\n",
    "acc_ip.write(ADDR_IN1_LOW, pa_in1 & 0xFFFFFFFF)\n",
    "acc_ip.write(ADDR_IN1_HIGH, pa_in1 >> 32)\n",
    "acc_ip.write(ADDR_OUT_LOW, pa_out & 0xFFFFFFFF)\n",
    "acc_ip.write(ADDR_OUT_HIGH, pa_out >> 32)\n",
    "print(\"DDR buffer addresses written to IP core.\\n\")\n",
    "\n",
    "print(\"--- Executing STAGE 0: Load data from DDR to on-chip memory ---\")\n",
    "run_stage_and_wait(stage=0)\n",
    "print(\"STAGE 0 complete.\\n\")\n",
    "\n",
    "results_summary = {}\n",
    "\n",
    "# 循环测试所有函数\n",
    "for func_name in FUNCTIONS_TO_TEST:\n",
    "    print(f\"--- Testing: {func_name} ---\")\n",
    "    opcode = OPCODE_MAP[func_name]\n",
    "    \n",
    "    # 计时 Stage 1 (计算)\n",
    "    t_start = time.time()\n",
    "    run_stage_and_wait(stage=1, config=opcode)\n",
    "    t_end = time.time()\n",
    "    latency_ms = (t_end - t_start) * 1000\n",
    "    \n",
    "    # 执行 Stage 2 (写回)\n",
    "    run_stage_and_wait(stage=2)\n",
    "    \n",
    "    # 从 DDR 读取结果\n",
    "    out_buffer.invalidate()\n",
    "    fpga_result_bits = out_buffer.copy()\n",
    "    \n",
    "    # 与黄金参考对比并计算分数\n",
    "    golden_ref_pt = golden_refs[func_name]\n",
    "    l2_error, acc_score, diff_count = calculate_accuracy_score(fpga_result_bits, golden_ref_pt)\n",
    "    \n",
    "    latency_s = latency_ms / 1000.0 # 将延迟从毫秒转换为秒\n",
    "    # 1. 计算有效吞吐率 (Tensors/sec)\n",
    "    tensors_per_second = 1.0 / latency_s if latency_s > 0 else 0\n",
    "    # 2. 计算有效内存带宽 (MB/s) - 衡量片上存储的交互速度\n",
    "    effective_bandwidth_MBs = (TOTAL_BYTES_MOVED / latency_s) / (1024 * 1024) if latency_s > 0 else 0\n",
    "    # 3. 计算算力 (GOPS) - 仅对 Elementwise 操作有明确意义\n",
    "    # SiLU 和 GELU 也是 Elementwise 的，其 GOPS 代表每秒执行函数次数\n",
    "    if func_name in ['Add', 'Mul', 'SiLU', 'GELU']:\n",
    "         gops = (TOTAL_ELEMENTWISE_OPS / latency_s) / 1e9 if latency_s > 0 else 0\n",
    "         gops_str = f\"{gops:.2f} GOPS\"\n",
    "    else: # 对于 Softmax 和 Norms, 包含复杂的 Reduction, GOPS 难以统一定义\n",
    "         gops_str = \"N/A (Reduction-based)\"\n",
    "    \n",
    "    results_summary[func_name] = {\n",
    "        \"latency_ms\": latency_ms,\n",
    "        \"l2_error\": l2_error,\n",
    "        \"accuracy_score\": acc_score,\n",
    "        \"diff_elements\": diff_count,\n",
    "        \"throughput_tensors_per_sec\": tensors_per_second, # <--- NEW\n",
    "        \"bandwidth_MBps\": effective_bandwidth_MBs,        # <--- NEW\n",
    "        \"gops_str\": gops_str                               # <--- NEW\n",
    "    }\n",
    "    \n",
    "    print(f\"  Latency (Stage 1): {latency_ms:.4f} ms\")\n",
    "    print(f\"  Relative L2 Error (εf): {l2_error:.6e}\")\n",
    "    print(f\"  Mismatched Elements (non-NaN): {diff_count}\")\n",
    "    print(f\"  Accuracy Score (Af): {acc_score:.6f}\")\n",
    "    # 打印新增的性能指标\n",
    "    print(f\"  ---------------- Performance Metrics -----------------\")\n",
    "    print(f\"  Clock Frequency (from report): {CLOCK_FREQ_MHZ:.1f} MHz\")\n",
    "    print(f\"  Throughput: {tensors_per_second:.2f} Tensors/sec\")\n",
    "    print(f\"  Effective On-Chip Bandwidth: {effective_bandwidth_MBs:.2f} MB/s\")\n",
    "    print(f\"  Compute Power: {gops_str}\")\n",
    "    print(f\"  ----------------------------------------------------\")\n",
    "\n",
    "    # ================================================================================\n",
    "    # [CORRECTED DEBUG BLOCK v2]\n",
    "    # Fixes the ValueError by providing the correct format specifier for scientific\n",
    "    # notation in Python f-strings (changed \":.e\" to \":.1e\").\n",
    "    # ================================================================================\n",
    "    if acc_score < 0.99999 and diff_count > 0:\n",
    "        print(\"  [DEBUG] Mismatch detected. Performing detailed row-by-row analysis...\")\n",
    "    \n",
    "        # --- 1. 配置常量 ---\n",
    "        ROW_ERROR_THRESHOLD = 1e-2\n",
    "        MAX_ROWS_TO_PRINT = 60\n",
    "        ELEMENTS_PER_ROW = 4\n",
    "    \n",
    "        # --- 2. 准备数据 ---\n",
    "        fpga_out_f32 = to_float32_from_bits(fpga_result_bits)\n",
    "        golden_ref_f32 = golden_ref_pt.to(torch.float32).cpu().numpy().flatten()\n",
    "        golden_ref_bits = golden_ref_pt.view(torch.int16).cpu().numpy().flatten()\n",
    "        input_a_bits = X_test_bits\n",
    "        input_b_bits = Y_test_bits if func_name in ['Add', 'Mul'] else None\n",
    "    \n",
    "        # --- 3. 逐行分析，找出所有出错的行和【真正】原因 ---\n",
    "        failing_rows_info = []\n",
    "        for i in range(N_DIM):\n",
    "            start_idx, end_idx = i * D_DIM, (i + 1) * D_DIM\n",
    "            fpga_row, golden_row = fpga_out_f32[start_idx:end_idx], golden_ref_f32[start_idx:end_idx]\n",
    "    \n",
    "            # [FIXED] 分别检查 NaN 和 Inf 不匹配\n",
    "            nan_mismatch = np.any(np.isnan(fpga_row) != np.isnan(golden_row))\n",
    "            inf_mismatch = np.any(np.isinf(fpga_row) != np.isinf(golden_row))\n",
    "    \n",
    "            # 计算纯数值L2误差\n",
    "            valid_indices = ~np.isnan(fpga_row) & ~np.isnan(golden_row) & \\\n",
    "                            ~np.isinf(fpga_row) & ~np.isinf(golden_row)\n",
    "            row_l2_error = 0.0\n",
    "            if np.any(valid_indices):\n",
    "                numerator = np.linalg.norm(fpga_row[valid_indices] - golden_row[valid_indices])\n",
    "                denominator = np.linalg.norm(golden_row[valid_indices])\n",
    "                if denominator > 1e-12: row_l2_error = numerator / denominator\n",
    "    \n",
    "            # [FIXED] 根据优先级记录失败原因\n",
    "            if nan_mismatch:\n",
    "                failing_rows_info.append({'idx': i, 'reason': 'NaN Mismatch'})\n",
    "            elif inf_mismatch:\n",
    "                failing_rows_info.append({'idx': i, 'reason': 'Inf Mismatch'})\n",
    "            elif row_l2_error > ROW_ERROR_THRESHOLD:\n",
    "                failing_rows_info.append({'idx': i, 'reason': f'High L2 Error ({row_l2_error:.2e})'})\n",
    "    \n",
    "        # --- 4. 生成最终的、清晰的调试报告 ---\n",
    "        if not failing_rows_info:\n",
    "            print(\"  [Analysis Result] A global mismatch was detected, but the per-row analysis script failed to pinpoint the cause.\")\n",
    "        else:\n",
    "            print(f\"  [Analysis Result] Found {len(failing_rows_info)} problematic rows.\")\n",
    "            rows_printed_count = 0\n",
    "            for info in failing_rows_info:\n",
    "                if rows_printed_count >= MAX_ROWS_TO_PRINT:\n",
    "                    print(\"  ... (more problematic rows exist but are not shown)\")\n",
    "                    break\n",
    "                \n",
    "                row_idx = info['idx']\n",
    "                print(f\"\\n  --- Details for Row {row_idx} (Reason: {info['reason']}) ---\")\n",
    "                \n",
    "                row_start_idx = row_idx * D_DIM\n",
    "                def format_val(bits):\n",
    "                    val = to_float32_from_bits(np.array([bits], dtype=np.uint16))[0]\n",
    "                    if np.isnan(val): return \"nan\"\n",
    "                    if np.isposinf(val): return \"+inf\"\n",
    "                    if np.isneginf(val): return \"-inf\"\n",
    "                    return f\"{val:<9.4f}\"\n",
    "    \n",
    "                for i in range(ELEMENTS_PER_ROW):\n",
    "                    idx = row_start_idx + i\n",
    "                    in_a_b, fpga_b, golden_b = input_a_bits[idx], fpga_result_bits[idx], golden_ref_bits[idx]\n",
    "                    \n",
    "                    print(f\"    - Idx {idx:<5d} (col {i:<2d}): In_A  = 0x{in_a_b:04x} ({format_val(in_a_b)})\", end=\"\")\n",
    "                    if input_b_bits is not None:\n",
    "                        in_b_b = input_b_bits[idx]\n",
    "                        print(f\" | In_B   = 0x{in_b_b:04x} ({format_val(in_b_b)})\", end=\"\")\n",
    "                    \n",
    "                    marker = \"FAIL\" if fpga_b != golden_b else \"  pass\"\n",
    "                    print(f\"\\n      {marker:^8s} -> HLS    = 0x{fpga_b:04x} ({format_val(fpga_b)})\")\n",
    "                    print(f\"               Golden = 0x{golden_b:04x} ({format_val(golden_b)})\")\n",
    "    \n",
    "                rows_printed_count += 1\n",
    "    \n",
    "    print(\"-\" * 25 + \"\\n\")\n",
    "print(\"Cell 4 finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b4aa1b0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==============================================================================================================\n",
      "                                   FPT'25 FINAL PERFORMANCE REPORT\n",
      "==============================================================================================================\n",
      "Function     | Latency(ms)    | Acc. Score   | Throughput(T/s)  | Bandwidth(MB/s)    | Compute(GOPS)       \n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Softmax      | 0.8447         | 0.972926     | 1183.83          | 221.97             | N/A (Reduction-based)\n",
      "LayerNorm    | 0.8254         | 1.000000     | 1211.53          | 227.16             | N/A (Reduction-based)\n",
      "RMSNorm      | 0.8476         | 1.000000     | 1179.83          | 221.22             | N/A (Reduction-based)\n",
      "SiLU         | 0.3107         | 1.000000     | 3218.96          | 603.55             | 0.16 GOPS           \n",
      "GELU         | 0.3164         | 1.000000     | 3160.74          | 592.64             | 0.16 GOPS           \n",
      "Add          | 0.3231         | 1.000000     | 3095.43          | 580.39             | 0.15 GOPS           \n",
      "Mul          | 0.3295         | 1.000000     | 3034.95          | 569.05             | 0.15 GOPS           \n",
      "==============================================================================================================\n",
      "\n",
      "* T/s: Tensors per second (64x768 bf16)\n",
      "* Bandwidth: Effective on-chip memory bandwidth (read + write)\n",
      "* GOPS: Giga Operations Per Second (for element-wise functions)\n",
      "\n",
      "Freeing PYNQ buffers...\n",
      "Test complete. Buffers freed.\n",
      "All cells finished\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n\" + \"=\" * 110)\n",
    "print(\" \" * 35 + \"FPT'25 FINAL PERFORMANCE REPORT\")\n",
    "print(\"=\" * 110)\n",
    "# 增强版的表头\n",
    "print(f\"{'Function':<12} | {'Latency(ms)':<14} | {'Acc. Score':<12} | {'Throughput(T/s)':<16} | {'Bandwidth(MB/s)':<18} | {'Compute(GOPS)':<20}\")\n",
    "print(\"-\" * 110)\n",
    "\n",
    "for func_name in FUNCTIONS_TO_TEST:\n",
    "    res = results_summary[func_name]\n",
    "    \n",
    "    # 准备用于打印的字符串\n",
    "    lat_str = f\"{res['latency_ms']:.4f}\"\n",
    "    acc_str = f\"{res['accuracy_score']:.6f}\"\n",
    "    throughput_str = f\"{res['throughput_tensors_per_sec']:.2f}\"\n",
    "    bandwidth_str = f\"{res['bandwidth_MBps']:.2f}\"\n",
    "    gops_str = res['gops_str']\n",
    "    print(f\"{func_name:<12} | {lat_str:<14} | {acc_str:<12} | {throughput_str:<16} | {bandwidth_str:<18} | {gops_str:<20}\")\n",
    "\n",
    "print(\"=\" * 110)\n",
    "print(\"\\n* T/s: Tensors per second (64x768 bf16)\")\n",
    "print(\"* Bandwidth: Effective on-chip memory bandwidth (read + write)\")\n",
    "print(\"* GOPS: Giga Operations Per Second (for element-wise functions)\")\n",
    "\n",
    "\n",
    "# 清理 PYNQ 缓冲区\n",
    "print(\"\\nFreeing PYNQ buffers...\")\n",
    "in0_buffer.close()\n",
    "in1_buffer.close()\n",
    "out_buffer.close()\n",
    "print(\"Test complete. Buffers freed.\")\n",
    "print(\"All cells finished\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
